# Parallel Programming Hw1 Report
### 11208530余雪淩
(需要在淺色模式下閱讀，圖表的文字才看得到)
## 1. Implemention


#### 1. 輸入資料處理
程式設計可以處理任意數量的輸入資料與 MPI process。假設輸入資料總數為 \( n \)，process數為 \( p \)，每個process大約處理 \( n/p ) 筆資料。如果 \( n mod p != 0 \)，部分process會多處理一筆資料。程式透過 `local_size`（每個process的資料量）與 `local_idx`（每個process的起始索引）來分配資料，保證分配的靈活性。

```c
int local_size = n / size + (rank < n % size);
int local_idx = n / size * rank + min(n % size, rank);
```
示意圖：
```
+------------+    +------------+    +------------+
| Process 0  |    | Process 1  |    | Process 2  |
| Items 0-4  |    | Items 5-9  |    | Items 10-14|
+------------+    +------------+    +------------+
```

#### 1.2 排序方法
每個process首先使用 `boost::sort::spreadsort::float_sort` 對其分配的資料進行初始排序。接著，程式利用`phase`紀錄並更新當前階段，使用平行的奇偶交換排序法（Odd-Even Transposition Sort）進行全局排序：

- **偶數階段**：每個process與右邊的鄰居交換資料，然後合併結果，保留較小的數值。
- **奇數階段**：每個process與左邊的鄰居交換資料，然後合併結果，保留較大的數值。
這種排序方法透過不斷進行偶數與奇數階段，確保全體process的資料達到排序。

##### 主要流程解釋

###### 1. **初始設定與參數**：
   ```cpp
   phase = rank % 2 == 1 ? 1 : 0;
   int t = size + 1;
   ```
   - `phase` 變數初始化：根據 `rank` 判斷是偶數還是奇數階段，這裡如果 rank 是奇數則設定為 1（奇數階段），偶數則設定為 0（偶數階段）。
   - `t` 執行 size + 1 次的交換階段可以保證所有 process 之間的數據都經過完整的比較和交換，從而使所有數據都能達到全局有序。

###### 2. **進入 while 迴圈進行排序階段**：
   ```cpp
   while (t--) { /* Sorting Phases */}
   ```
   `while` 迴圈會在 `t` 倒數到 0 時結束。每次迴圈執行一次排序階段。

###### 3. **交換與合併(以Even phase為例)**：
   ```cpp
   if (phase == 0 && rank + 1 < size && rsize > 0 && local_size > 0) {
   ```
   - 判斷條件：只有在偶數階段且該 process 不是最後一個 rank 時，才會進行右邊的相鄰 process 間的資料交換。
   - `MPI_Sendrecv`：交換資料。這裡當 `rank` 符合條件時，透過 `MPI_Sendrecv` 將當前 `rank` 的 `local_data` 發送到右邊的 `rank + 1`，並從 `rank + 1` 接收相鄰 process 的資料到 `rdata`。
   
###### 4. **合併排序**：
   ```cpp
   int i = 0, r = 0, l = 0;
   while(i < local_size && r < rsize && l < local_size) {
       if (local_data[l] < rdata[r]) {
           tmp[i] = local_data[l]; i++; l++;
       } else {
           tmp[i] = rdata[r]; i++; r++;
       }
   }
   ```
   - 使用 `i`、`r` 和 `l` 作為索引，分別指向結果 `tmp`、`rdata` 和 `local_data` 的位置。
   - 比較 `local_data` 和 `rdata` 中的值，依序將較小的值放入 `tmp` 中，直到其中一個資料集遍歷完成。

###### 5. **處理剩餘資料**：
   ```cpp
   if (l == local_size) {
       while (i != local_size) {
           tmp[i] = rdata[r]; i++; r++;
       }
   }
   if (r == rsize) {
       while (i != local_size) {
           tmp[i] = local_data[l]; i++; l++;
       }
   }
   ```
   - 當 `local_data` 或 `rdata` 中的元素已經全部放入 `tmp`，這段程式處理剩下的資料。
   - 逐個將尚未放入的資料補充進 `tmp`。

###### 6. **更新本地排序結果**：
   ```cpp
   std::swap(tmp, local_data);
   ```
   - 這行將合併排序好的 `tmp` 資料交換到 `local_data` 中，以便在下一階段中繼續進行排序。




#### 1.3 Improvement
- **Boost Spreadsort 排序**：在每個process的本地排序中使用 Boost 的 `spreadsort` 演算法以提升float的排序效率。
- **動態緩衝區分配**：針對相鄰process資料交換進行動態記憶體分配，以減少記憶體佔用。只在需要交換資料時根據實際情況分配記憶體，而不是一次性分配固定的較大空間。
```c
int rsize = local_size - (rank + 1 == n % size);
int lsize = local_size + (rank == (n % size));
float* rdata = new float[rsize];
float* ldata = new float[lsize];
```
- **降低溝通時間**：使用`MPI_Sendrecv`同時發送跟接收訊息以減少溝通時間

---

### 2. Experiment & Analysis

#### 2.1 Methodology

**System Spec**：
課程提供的Apollo server，使用mpi module編譯。
**Performance Metrics**：
- **computing time**：記錄每個process執行本地排序（Boost Spreadsort）以及奇偶交換排序時的耗時。
- **communication time**：使用NVTX標記每次 `MPI_Sendrecv` 操作的通訊時間。
- **I/O time**：記錄使用 `MPI_File_open` 和 `MPI_File_write_at` 進行平行 I/O 操作的時間。

#### 2.2 Plots: Speedup Factor & Profile

**Experimental Method**：
- **Test Case Description**：選擇536869888筆隨機生成的浮點數作為測試數據量（testcase 37）。
- **Parallel Configurations**：選擇在 1、2、4、8、16 個process上分別進行單節點與4節點測試，並記錄每種配置下的運行時間。
- **Performance Measurement**：使用 `nsys` 進行通訊和計算的細部剖析，並記錄不同階段的執行時間。
  
**Results and analysis**：
- **Time Profile**：
<div style="display: flex; align-items: center;">
    <img src="https://hackmd.io/_uploads/BJ8NfDXZJx.png" alt="fast04" width="50%" style="margin-right: 10px;">
    <img src="https://hackmd.io/_uploads/ryXqMOXWJe.png)" alt="strict08" width="50%">
</div>

MPI overhead主要為MPI Initialize和MPI Finalize時間

- **Speedup**：
<div style="display: flex; align-items: center;">
    <img src="https://hackmd.io/_uploads/HkFnfu7W1l.png" alt="fast04" width="50%" style="margin-right: 10px;">
    <img src="https://hackmd.io/_uploads/ryKpz_X-Jl.png)" alt="strict08" width="50%">
</div>

#### 2.3 Optimization

在此次實驗中，各 rank 的計算時間較為均勻，顯示出良好的load balance。但根據結果分析，I/O 和通訊開銷佔據了較大的比例，尤其是在多 process下，隨著 process 數量的增加，I/O 和通訊的開銷更為明顯。因此，以下是可能的幾個優化策略：


1. **合併通訊**：減少頻繁使用`MPI_Sendrecv`，通過合併多次交換數據的需求，降低每次通訊的頻率，以此減少通訊開銷。
在目前的程式中，是無論任何情況都會交換兩個neighbor的整筆資料
```c
if (phase == 0 && rank + 1 < size && rsize > 0 && local_size > 0) {
            
    MPI_Sendrecv(local_data, local_size, MPI_FLOAT, rank + 1, 0, rdata, rsize, MPI_FLOAT, rank + 1, 0, comm, MPI_STATUS_IGNORE);
            
```
若能先判斷是否需要換整筆資料，例如先判斷是否右鄰居的第一個數字>=當前鄰居的最後一個數字，如果這個情況成立，則不必完整交換兩筆資料。如此一來應能大幅降低通訊時間

2. **減少 MPI Barrier 使用**：在必要的位置才使用 MPI_Barrier，避免不必要的同步操作，從而減少全局同步帶來的延遲。
**實作**:原本在執行完所有odd-even sort時，有放MPI barrier，拿掉之後scoreboard的執行時間從<font color='green'> {121.16} --> {117.19} </font>


### 3. Discussion

* **Computation time**:
無論是在單節點還是多節點，可以看到computation time確實隨著process增加而減少，但因為隨著process數增加，通訊次數也隨之增加，computation time也會跟著增加，成為computation time的瓶頸。
* **I/O time**:
I/O time在各情況下均佔一定時間，尤其在多節點情況下時間大幅增加，變化幅度也很大，推測除了受到bandwidth限制無法提升，成為bottleneck外，還有可能有多processes間的競爭問題，導致I/O時間在多節點下大幅增加，而在16個processes時間反而比32還多有可能是I/O scheduler在不同情況下的分配導致。

* **Communication time**:
Communication time 變化量較小，但仍然有隨著processes數增加而變多的趨勢，因為processes增加，需要溝通的次數也變多，而若是碰到需要跨跑在不同機器上的節點溝統，那時間可能又會更多。

* **Scalability**
無論是在單節點或多節點上，overall speedup由於受I/O和通訊時間的影響，與ideal speedup差距非常大，主要是因為通訊和 I/O 開銷佔比逐漸增加，導致平行效率降低。雖然計算速度有所提升，但通訊和 I/O 成為限制scalability的瓶頸。但在computation speedup的表現中，雖然受到Communication time的影響，隨著process數量增加而增加與ideal的差距，但整體還是呈線性增加。

整體來說，I/O 和通訊開銷成為主要瓶頸，未能隨process數量增長而線性加速，反而增加了等待和同步時間。I/O 開銷尤其在多 process 下呈現明顯的增長趨勢，可能是因為每個 process 進行頻繁的 I/O 操作造成的資源競爭。未來可嘗試從減少I/O或通訊時間進行優化，比較方便的是降低`MPI_Sendrecv`的次數，使得系統可以更高效地處理資料傳輸。


### Experiences / Conclusion

本次實作練習使用MPI平行化排序演算法的效果。在大規模資料集下，程式在加速比和負載均衡方面表現良好，但受限於 I/O 和通訊時間，難以達到線性增長的理想加速效果。
透過此實作，學習了如何將 Boost Sort 與 MPI 結合應用，過程中覺得最困難的地方是處理MPI的溝通問題，花了很多時間debug並思考可能出錯的條件，在優化通訊效率上也遇到了一些bug，導致來不及做出最終優化的版本，雖然此次程式跑出來的效果沒有很滿意，但也在過程中學到很多，希望這次的經驗能成為往後更精進的養分。
